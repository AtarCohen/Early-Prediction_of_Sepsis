{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OmriShemTov Hatich Shel Yeled\n"
     ]
    }
   ],
   "source": [
    "print(\"OmriShemTov Hatich Shel Yeled\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc(\"font\", size=14)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "sns.set(style=\"white\")\n",
    "sns.set(style=\"whitegrid\", color_codes=True)\n",
    "from sklearn.impute import KNNImputer\n",
    "from imblearn.over_sampling import SMOTE ##TODO: Insert to ENV.yml\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import statsmodels.api as sm\n",
    "import random\n",
    "seed=42\n",
    "random.seed(seed)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def lr_preprocess_sepsis(df, window_size=5, time_bm=-10):\n",
    "\n",
    "    # columns for using\n",
    "    frequency_used_attributes = ['BaseExcess',  'FiO2', 'pH', 'PaCO2', 'Glucose','Lactate', 'PTT']\n",
    "    values_used_attributes = [ 'Hct', 'Glucose','Potassium']\n",
    "    constant_attributes = ['ID','max_ICULOS', 'Gender']\n",
    "    other_attributes = ['time_bm','HR','MAP','O2Sat', 'Resp','SBP', 'ICULOS']\n",
    "    units_attributes = ['Unit1', 'Unit2']\n",
    "    label_attributes= ['Label','SepsisLabel']\n",
    "\n",
    "    # create frequency columns for some lab variables\n",
    "    def add_rolling_window(df, attr, window_size):\n",
    "        df = df.sort_values(by=['ID','ICULOS'], ascending =[True,True])\n",
    "        rolling = df[['ID']+attr].groupby('ID').rolling(window=window_size, closed='both').count()\n",
    "        rolling= rolling.rename(columns={at: f'{window_size}w_sum_{at}' for at in attr})\n",
    "        rolling=rolling[list(rolling.columns)[1:]].reset_index().set_index('level_1')\n",
    "        combined = df.join(rolling,how='left', rsuffix= 'r')\n",
    "        return combined, rolling\n",
    "    df_with_roll, df_roll = add_rolling_window(df,frequency_used_attributes,window_size)\n",
    "    frequency_used_attributes_fixed = [f'{window_size}w_sum_{x}' for x in frequency_used_attributes]\n",
    "    df_with_roll = df_with_roll[constant_attributes + other_attributes + \\\n",
    "                                        values_used_attributes + frequency_used_attributes_fixed + \\\n",
    "                                        units_attributes + label_attributes]\n",
    "\n",
    "    # crop 10 (time_bm) last ICULOS hours for each patient\n",
    "    df_with_roll = df_with_roll[df_with_roll['time_bm']>=time_bm]\n",
    "\n",
    "    # handle Units123\n",
    "    df_with_roll['Unit3'] = ( (1*(df_with_roll['Unit1']+df_with_roll['Unit2'])<1) |\n",
    "                          (df_with_roll['Unit1'].isna() & df_with_roll['Unit2'].isna()) )*1\n",
    "    df_with_roll['Unit1'][df_with_roll['Unit1'].isna()] = 0\n",
    "    df_with_roll['Unit2'][df_with_roll['Unit2'].isna()] = 0\n",
    "    df_with_roll[['Unit1','Unit2','Unit3']]\n",
    "\n",
    "    # aggregations\n",
    "    data_final = df_with_roll.groupby(['ID', 'Label','max_ICULOS','Gender']).agg({\n",
    "                                                        'Unit1': 'max',\\\n",
    "                                                        'Unit2': 'max',\\\n",
    "                                                        'Unit3': 'max',\\\n",
    "                                                        'HR': ['median', 'max'],\\\n",
    "                                                        'MAP': ['median', 'min'],\\\n",
    "                                                        'O2Sat': ['mean'],\\\n",
    "                                                        'Resp': ['median', 'max'],\\\n",
    "                                                        'SBP': ['median', 'min'],\\\n",
    "                                                        'Hct': ['median', 'min'],\\\n",
    "                                                        'Potassium': 'mean',\\\n",
    "                                                        'Glucose': 'mean',\\\n",
    "                                                        f'{window_size}w_sum_BaseExcess': 'mean',\\\n",
    "                                                        f'{window_size}w_sum_FiO2': 'mean',\\\n",
    "                                                        f'{window_size}w_sum_pH': 'mean',\\\n",
    "                                                        f'{window_size}w_sum_PaCO2': 'mean',\\\n",
    "                                                        f'{window_size}w_sum_Glucose': 'mean',\\\n",
    "                                                        f'{window_size}w_sum_Lactate': 'mean',\\\n",
    "                                                        f'{window_size}w_sum_PTT': 'mean'}).reset_index()\n",
    "    data_final.columns = ['__'.join(col).strip() for col in data_final.columns.values]\n",
    "    data_final.rename(columns={\"ID__\": \"ID\", \"Label__\": \"Label\", \"max_ICULOS__\":\"max_ICULOS\", \"Gender__\":\"Gender\"}, inplace=True)\n",
    "\n",
    "    return data_final\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def imputation_with_KNNimputer(train_df, n=3):\n",
    "    data_knn_imputed = train_df.copy(deep=True)    # Copy the data\n",
    "    knn_imp = KNNImputer(n_neighbors=n) # Init the transformer\n",
    "    knn_imp.fit(data_knn_imputed)\n",
    "    return knn_imp"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def os_with_smote(train_df, p=0.5):\n",
    "    X = train_df.loc[:, train_df.columns != 'Label']\n",
    "    y = train_df.loc[:, train_df.columns == 'Label']\n",
    "    os = SMOTE(sampling_strategy=p, random_state=0)\n",
    "    columns = X.columns\n",
    "    os_data_X, os_data_y = os.fit_resample(X, y)\n",
    "    os_data_X = pd.DataFrame(data=os_data_X,columns=columns )\n",
    "    os_data_y = pd.DataFrame(data=os_data_y,columns=['Label'])\n",
    "    return os_data_X, os_data_y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"/home/student/filtered_train_df_0705.csv\")\n",
    "val_df = pd.read_csv(\"/home/student/filtered_val_df_0705.csv\")\n",
    "test_df =  pd.read_csv(\"/home/student/filtered_test_df_0705.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda3/lib/python3.8/site-packages/pandas/core/window/rolling.py:2010: FutureWarning: min_periods=None will default to the size of window consistent with other methods in a future version. Specify min_periods=0 instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of train data is 16000\n",
      "Number of Label=0 in train data 14857\n",
      "Number of Label=1 in train data 1143\n",
      "Proportion of Label=0 data in train data is  0.9285625\n",
      "Proportion of Label=1 data in train data is  0.0714375\n"
     ]
    }
   ],
   "source": [
    "train_df = lr_preprocess_sepsis(train_df)\n",
    "# Check the numbers of our data\n",
    "print(\"length of train data is\",len(train_df))\n",
    "print(\"Number of Label=0 in train data\",len(train_df[train_df['Label']==0]))\n",
    "print(\"Number of Label=1 in train data\",len(train_df[train_df['Label']==1]))\n",
    "print(\"Proportion of Label=0 data in train data is \",len(train_df[train_df['Label']==0])/len(train_df))\n",
    "print(\"Proportion of Label=1 data in train data is \",len(train_df[train_df['Label']==1])/len(train_df))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# imputing training data\n",
    "# TODO: Save Imputer\n",
    "knn_imp = imputation_with_KNNimputer(train_df, 3)\n",
    "train_df.loc[:, :] = knn_imp.transform(train_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of oversampled data is  18571\n",
      "Number of Label=0 in oversampled data 14857\n",
      "Number of Label=1 3714\n",
      "Proportion of Label=0 data in oversampled data is  0.8000107694792957\n",
      "Proportion of Label=1 data in oversampled data is  0.19998923052070433\n"
     ]
    }
   ],
   "source": [
    "# over-sampling training data\n",
    "X, y = os_with_smote(train_df, p=0.25)\n",
    "\n",
    "# Check the numbers of our data\n",
    "print(\"length of oversampled data is \",len(X))\n",
    "print(\"Number of Label=0 in oversampled data\",len(y[y['Label']==0]))\n",
    "print(\"Number of Label=1\",len(y[y['Label']==1]))\n",
    "print(\"Proportion of Label=0 data in oversampled data is \",len(y[y['Label']==0])/len(X))\n",
    "print(\"Proportion of Label=1 data in oversampled data is \",len(y[y['Label']==1])/len(X))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of final training data is  11142\n",
      "Number of Label=0 in final training data 7428\n",
      "Number of Label=1 3714\n",
      "Proportion of Label=0 data in final data training is  0.6666666666666666\n",
      "Proportion of Label=1 data in final training data is  0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "#Downsample majority class\n",
    "under = RandomUnderSampler(sampling_strategy=0.5)\n",
    "X,y = under.fit_resample(X, y)\n",
    "\n",
    "# Check the numbers of our data\n",
    "print(\"length of final training data is \",len(X))\n",
    "print(\"Number of Label=0 in final training data\",len(y[y['Label']==0]))\n",
    "print(\"Number of Label=1\",len(y[y['Label']==1]))\n",
    "print(\"Proportion of Label=0 data in final data training is \",len(y[y['Label']==0])/len(X))\n",
    "print(\"Proportion of Label=1 data in final training data is \",len(y[y['Label']==1])/len(X))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda3/lib/python3.8/site-packages/pandas/core/window/rolling.py:2010: FutureWarning: min_periods=None will default to the size of window consistent with other methods in a future version. Specify min_periods=0 instead.\n",
      "  warnings.warn(\n",
      "/data/anaconda3/lib/python3.8/site-packages/pandas/core/window/rolling.py:2010: FutureWarning: min_periods=None will default to the size of window consistent with other methods in a future version. Specify min_periods=0 instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "val_df = lr_preprocess_sepsis(val_df)\n",
    "val_df.loc[:, :] = knn_imp.transform(val_df)\n",
    "\n",
    "test_df = lr_preprocess_sepsis(test_df)\n",
    "test_df.loc[:, :] = knn_imp.transform(test_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "X_val = val_df.loc[:, val_df.columns != 'Label']\n",
    "y_val = val_df.loc[:, val_df.columns == 'Label']\n",
    "\n",
    "X_test = test_df.loc[:, test_df.columns != 'Label']\n",
    "y_test = test_df.loc[:, test_df.columns == 'Label']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.553699\n",
      "         Iterations 6\n",
      "                              Results: Logit\n",
      "===========================================================================\n",
      "Model:                  Logit               Pseudo R-squared:    0.130     \n",
      "Dependent Variable:     Label               AIC:                 12390.6238\n",
      "Date:                   2022-05-09 10:14    BIC:                 12580.9042\n",
      "No. Observations:       11142               Log-Likelihood:      -6169.3   \n",
      "Df Model:               25                  LL-Null:             -7092.0   \n",
      "Df Residuals:           11116               LLR p-value:         0.0000    \n",
      "Converged:              1.0000              Scale:               1.0000    \n",
      "No. Iterations:         6.0000                                             \n",
      "---------------------------------------------------------------------------\n",
      "                         Coef.   Std.Err.    z     P>|z|   [0.025   0.975] \n",
      "---------------------------------------------------------------------------\n",
      "ID                       -0.0000   0.0000  -6.3662 0.0000  -0.0000  -0.0000\n",
      "max_ICULOS                0.0073   0.0007  10.3065 0.0000   0.0059   0.0087\n",
      "Gender                    0.1932   0.0471   4.1012 0.0000   0.1009   0.2855\n",
      "Unit1__max              -11.7243   1.1115 -10.5481 0.0000 -13.9028  -9.5458\n",
      "Unit2__max              -12.2153   1.1119 -10.9862 0.0000 -14.3945 -10.0361\n",
      "Unit3__max              -11.8329   1.1132 -10.6296 0.0000 -14.0147  -9.6510\n",
      "HR__median                0.0242   0.0033   7.3606 0.0000   0.0177   0.0306\n",
      "HR__max                  -0.0039   0.0029  -1.3343 0.1821  -0.0096   0.0018\n",
      "MAP__median              -0.0384   0.0047  -8.2151 0.0000  -0.0475  -0.0292\n",
      "MAP__min                  0.0264   0.0045   5.8955 0.0000   0.0176   0.0351\n",
      "O2Sat__mean               0.0881   0.0104   8.4793 0.0000   0.0677   0.1084\n",
      "Resp__median              0.0746   0.0084   8.8405 0.0000   0.0581   0.0912\n",
      "Resp__max                -0.0224   0.0060  -3.7169 0.0002  -0.0342  -0.0106\n",
      "SBP__median               0.0135   0.0030   4.5539 0.0000   0.0077   0.0194\n",
      "SBP__min                 -0.0112   0.0030  -3.6845 0.0002  -0.0172  -0.0052\n",
      "Hct__median               0.0156   0.0332   0.4700 0.6384  -0.0495   0.0807\n",
      "Hct__min                  0.0011   0.0324   0.0344 0.9726  -0.0624   0.0647\n",
      "Potassium__mean          -0.0476   0.0502  -0.9494 0.3424  -0.1459   0.0507\n",
      "Glucose__mean             0.0023   0.0006   3.8436 0.0001   0.0011   0.0035\n",
      "5w_sum_BaseExcess__mean  -0.1191   0.1114  -1.0694 0.2849  -0.3373   0.0992\n",
      "5w_sum_FiO2__mean         0.6231   0.0398  15.6736 0.0000   0.5452   0.7010\n",
      "5w_sum_pH__mean          -0.1143   0.1292  -0.8842 0.3766  -0.3676   0.1390\n",
      "5w_sum_PaCO2__mean        0.3200   0.1265   2.5291 0.0114   0.0720   0.5680\n",
      "5w_sum_Glucose__mean     -0.3224   0.0316 -10.2002 0.0000  -0.3844  -0.2605\n",
      "5w_sum_Lactate__mean      0.7192   0.0861   8.3564 0.0000   0.5505   0.8879\n",
      "5w_sum_PTT__mean          0.0813   0.0906   0.8975 0.3694  -0.0963   0.2589\n",
      "===========================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logit_model = sm.Logit(y,X)\n",
    "result = logit_model.fit()\n",
    "print(result.summary2())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/student/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": "LogisticRegression()"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X, y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "y_pred = logreg.predict(X_val)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on test set: 0.91\n",
      "exact: 0.91425\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_val, y_val)))\n",
    "print(f\"exact: {(val_df['Label']==y_pred).mean()}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "0.91425"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(val_df['Label']==y_pred).mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val F1:  0.5901726263392947\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print('Val F1: ', f1_score(y_val, y_pred, average='macro'))\n",
    "\n",
    "# print(f1_score(y_val, y_pred, average='micro'))\n",
    "# print(f1_score(y_val, y_pred, average='weighted'))\n",
    "# print(f1_score(y_val, y_pred, average=None))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.9951298701298701\n",
      "Val F1: 0.7441860465116278\n",
      "Val F1: 0.690576652601969\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgbc = XGBClassifier()\n",
    "xgbc.fit(X, y)\n",
    "y_train_pred = xgbc.predict(X)\n",
    "print(f'Train F1: {f1_score(y,y_train_pred)}')\n",
    "y_val_pred = xgbc.predict(X_val)\n",
    "print(f'Val F1: {f1_score(y_val,y_val_pred)}')\n",
    "y_test_pred = xgbc.predict(X_test)\n",
    "print(f'Val F1: {f1_score(y_test,y_test_pred)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-21-47a80e9ee28e>:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf.fit(X,y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 1.0\n",
      "Val F1: 0.7269230769230769\n",
      "Val F1: 0.6990014265335237\n"
     ]
    }
   ],
   "source": [
    "#Import Random Forest Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#Create a Gaussian Classifier\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(X,y)\n",
    "y_train_pred = clf.predict(X)\n",
    "print(f'Train F1: {f1_score(y, y_train_pred)}')\n",
    "y_val_pred = clf.predict(X_val)\n",
    "print(f'Val F1: {f1_score(y_val, y_val_pred)}')\n",
    "y_test_pred = clf.predict(X_test)\n",
    "print(f'Val F1: {f1_score(y_test, y_test_pred)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "# clf.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}