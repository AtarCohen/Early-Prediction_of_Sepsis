{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<h1> Prepare Data </h1>\n",
    "To prepare the data for our models we need to:\n",
    "<ol>\n",
    "<li> cut unnecessary rows from the csv's (the rows that will not be used as input for the model, as explained in the instructions) </li>\n",
    "<li> create train and validation datasets </li>\n",
    "</ol>\n",
    "<h2> Adding Columns </h2>\n",
    "For each patients (and row) we will add 3 columns to the data frame:\n",
    "<ol>\n",
    "<li> max_ICULOS - the total time a patient was in the ICU </li>\n",
    "<li> time_bm - the difference between the current time and the total time a patient was in the ICU. defined as $time_bm = ICULOS-max ICULOS$\n",
    "</li>\n",
    "<li> Label column -  1 if the patient had sepsis after some time in the ICU and 0 otherwise\n",
    "</li>\n",
    "</ol>\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import tqdm\n",
    "from random import sample\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from DataPreaparators import create_patients_df, DataPreparator"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "TRAIN_PATH = 'filtered_train_df_0705'\n",
    "VAL_PATH = 'filtered_val_df_0705'\n",
    "TEST_PATH = 'filtered_test_df_0705'\n",
    "TRAIN_MEAN_PATH = 'filtered_train_mean.csv'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# def create_patients_df(patients, data_path):\n",
    "#     tmp_df = pd.read_csv(os.path.join(data_path,patients[0]),delimiter ='|')\n",
    "#     tmp_df['ID'] = patients[0].split('_')[-1].split('.')[0]\n",
    "#     new_df = tmp_df[tmp_df['SepsisLabel']==0]\n",
    "#     if max(tmp_df['SepsisLabel'])==1:\n",
    "#         new_df=new_df.append(tmp_df[tmp_df['SepsisLabel']==1][:1])\n",
    "#         new_df['Label'] = [1]*new_df.shape[0]\n",
    "#     else:\n",
    "#         new_df['Label'] = [0]*new_df.shape[0]\n",
    "#     new_df['max_ICULOS'] = [new_df['ICULOS'].values[-1]]*new_df.shape[0]\n",
    "#     new_df['time_bm'] =  new_df['ICULOS']-new_df['max_ICULOS']\n",
    "#     for patient in tqdm.tqdm(patients[1:]):\n",
    "#         patient_path = os.path.join(data_path,patient)\n",
    "#         patient_number = patient.split('_')[-1].split('.')[0]\n",
    "#         tmp_df = pd.read_csv(os.path.join(data_path,patient_path),delimiter ='|')\n",
    "#         tmp_df['ID'] = patient_number\n",
    "#         tmp_new_df = tmp_df[tmp_df['SepsisLabel']==0]\n",
    "#         if max(tmp_df['SepsisLabel'])==1:\n",
    "#             tmp_new_df=tmp_new_df.append(tmp_df[tmp_df['SepsisLabel']==1][:1])\n",
    "#             tmp_new_df['Label'] = [1]*tmp_new_df.shape[0]\n",
    "#         else:\n",
    "#             tmp_new_df['Label'] = [0]*tmp_new_df.shape[0]\n",
    "#         tmp_new_df['max_ICULOS'] = [tmp_new_df['ICULOS'].values[-1]]*tmp_new_df.shape[0]\n",
    "#         tmp_new_df['time_bm'] =  tmp_new_df['ICULOS']-tmp_new_df['max_ICULOS']\n",
    "#         new_df = new_df.append(tmp_new_df)\n",
    "#     return new_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# for d_type in ['train', 'test']:\n",
    "#     data_path = f'/home/student/Early_Prediction_of_Sepsis/data/{d_type}/'\n",
    "#     patients = os.listdir(f'data/{d_type}')\n",
    "#     if d_type=='train':\n",
    "#         train_patients = sample(patients,int(len(patients)*0.8))\n",
    "#         val_patients = [x for x in patients if x not in train_patients]\n",
    "#         train_df = create_patients_df(train_patients,data_path)\n",
    "#         train_df.to_csv(f'{TRAIN_PATH}.csv',index=False)\n",
    "#         val_df = create_patients_df(val_patients,data_path)\n",
    "#         val_df.to_csv(f'{VAL_PATH}.csv',index=False)\n",
    "#     else:\n",
    "#         test_df = create_patients_df(patients,data_path)\n",
    "#         test_df.to_csv(f'{TEST_PATH}.csv',index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "frequency_used_attributes = ['BaseExcess',  'FiO2', 'pH', 'PaCO2', 'Glucose','Lactate', 'PTT']\n",
    "# FREQUENCY_ATTR =['5w_sum_BaseExcess', '5w_sum_FiO2', '5w_sum_pH', '5w_sum_PaCO2', '5w_sum_Glucose', '5w_sum_Lactate', '5w_sum_PTT']\n",
    "# LAB_ATTR = ['Hct',  'Glucose','Potassium']\n",
    "CONST_ATTR = ['max_ICULOS','Gender']\n",
    "OTHER_ATTR = ['HR','MAP','O2Sat', 'Resp','SBP','ICULOS']\n",
    "ALL_LAB_ATTR = ['BaseExcess', 'HCO3', 'FiO2', 'pH', 'PaCO2',\n",
    " 'SaO2', 'AST', 'BUN', 'Alkalinephos', 'Calcium', 'Chloride',\n",
    " 'Creatinine', 'Bilirubin_direct', 'Glucose', 'Lactate',\n",
    " 'Magnesium', 'Phosphate', 'Potassium', 'Bilirubin_total',\n",
    " 'TroponinI', 'Hct', 'Hgb', 'PTT', 'WBC', 'Fibrinogen','Platelets']\n",
    "COLS = CONST_ATTR+OTHER_ATTR"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2> RNN Pre Process </h2>\n",
    "\n",
    "In order to use the data as input for RNN models we need some additional pre process and imputation, as explained in the report.\n",
    "The DataPreparator class will add frequency and window columns and will use iterative imputer to impute each patient missing data."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class DataPreparator():\n",
    "\n",
    "    def __init__(self,columns,window_columns=None, freq_columns=None, seq_len=10,window=5):\n",
    "        self.all_data_means= pd.read_csv(TRAIN_MEAN_PATH)\n",
    "        self.seq_len=seq_len\n",
    "        self.window = window\n",
    "        self.window_columns = window_columns\n",
    "        self.freq_columns = freq_columns\n",
    "        self.freq_columns_final =  [f'freq_{at}' for at in self.freq_columns]\n",
    "        self.columns = columns\n",
    "\n",
    "    def impute_per_patient(self,df):\n",
    "        patients = list(set(df.ID.values))\n",
    "        imputed = pd.DataFrame()\n",
    "        for patient in patients:\n",
    "            tmp_df = df[df['ID']==patient][self.columns+self.freq_columns_final+['time_bm']]\n",
    "            # tmp_labels = df[df['ID']==patient]['Label']\n",
    "            for f in self.columns:\n",
    "                if tmp_df[f].isnull().all:\n",
    "                    mean_val = self.all_data_means[self.all_data_means['index']==f]['0'].values[0]\n",
    "                    tmp_df[f]=tmp_df[f].fillna(mean_val)\n",
    "            imp = IterativeImputer(max_iter=50, random_state=0)\n",
    "            # try:\n",
    "            imp.fit(tmp_df)\n",
    "            tmp_df= pd.DataFrame(imp.transform(tmp_df), columns = self.columns+self.freq_columns_final+['time_bm'])\n",
    "            tmp_df['Label'] = df[df['ID']==patient]['Label'].values\n",
    "            tmp_df['ID'] = [patient]*tmp_df.shape[0]\n",
    "            imputed=imputed.append(tmp_df)\n",
    "        return imputed\n",
    "\n",
    "    def add_rolling_window(self,df):\n",
    "        df = df.sort_values(by=['ID','ICULOS'], ascending =[True,True])\n",
    "        rolling = df[['ID']+self.window_columns].groupby('ID').rolling(window=self.window, closed='both').count()\n",
    "        rolling= rolling.rename(columns={at: f'{self.window}w_sum_{at}' for at in self.window_columns})\n",
    "        rolling=rolling[list(rolling.columns)[1:]].reset_index().set_index('level_1')\n",
    "        combined = df.join(rolling,how='left', rsuffix= 'r')\n",
    "        self.columns +=[f'{self.window}w_sum_{at}' for at in self.window_columns]\n",
    "        return combined\n",
    "\n",
    "    def add_frequency(self,df):\n",
    "        df = df.sort_values(by=['ID', 'ICULOS'], ascending=[True, True])\n",
    "        rolling = df[['ID','ICULOS']+self.freq_columns].groupby(by=['ID'])[self.freq_columns].expanding().count().reset_index().rename(columns={'level_1':'old_index'})\n",
    "        df=df.reset_index().rename(columns={'index':'old_index'})\n",
    "        rolling = rolling.rename(columns={at: f'freq_{at}' for at in self.freq_columns})\n",
    "        combined = pd.merge(df,rolling, on=['ID','old_index'])\n",
    "        for at in self.freq_columns_final:\n",
    "            combined[at] = combined[at] / combined['ICULOS']\n",
    "        return combined\n",
    "\n",
    "    def prepare_data(self,df, rolling=False,freq=True):\n",
    "        if rolling:\n",
    "            df = self.add_rolling_window(df)\n",
    "        if freq:\n",
    "            df = self.add_frequency(df)\n",
    "        df = df[df['time_bm']>=-1*(self.seq_len)]\n",
    "        df = df[self.columns+self.freq_columns_final+['time_bm','ID','Label']]\n",
    "        df = self.impute_per_patient(df)\n",
    "        return df\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To impute features data for patient who have some all NULL values in some feature, we use mean imputation using the train mean value for this feature"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# train_df = pd.read_csv(f'{TRAIN_PATH}.csv')\n",
    "# all_data_mean = train_df.mean().reset_index().to_csv(TRAIN_MEAN_PATH,index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "p = DataPreparator(columns=COLS,freq_columns=ALL_LAB_ATTR)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(f'{TRAIN_PATH}.csv')\n",
    "train_df = p.prepare_data(train_df,rolling=False, freq=True)\n",
    "train_df.to_csv(f'{TRAIN_PATH}_LSTM_new.csv',index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "val_df = pd.read_csv(f'{VAL_PATH}.csv')\n",
    "val_df = p.prepare_data(val_df)\n",
    "val_df.to_csv(f'{VAL_PATH}_LSTM_new.csv',index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(f'{TEST_PATH}.csv')\n",
    "test_df = p.prepare_data(test_df)\n",
    "test_df.to_csv(f'{TEST_PATH}_LSTM_new.csv',index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}